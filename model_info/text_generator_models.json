[
    {"name": "models/gemini-1.0-pro",
     "Version": "001",
     "display_name": "Gemini 1.0 Pro",
     "Description": "The best model for scaling across a wide range of tasks",
     "Input Token Limit": 30720,
     "Output Token Limit": 2048,
     "Supported Generation Methods": ["generateContent", "countTokens"],
     "Temperature": 0.9,
     "Top P": 1.0,
     "Top K":  null},
    {"name": "models/gemini-1.0-pro-001",
     "Version": "001",
     "display_name": "Gemini 1.0 Pro 001 (Tuning)",
     "Description": "The best model for scaling across a wide range of tasks. This is a stable model that supports tuning.",
     "Input Token Limit": 30720,
     "Output Token Limit": 2048,
     "Supported Generation Methods": ["generateContent",
      "countTokens",
      "createTunedModel"],
     "Temperature": 0.9,
     "Top P": 1.0,
     "Top K":  null},
    {"name": "models/gemini-1.0-pro-latest",
     "Version": "001",
     "display_name": "Gemini 1.0 Pro Latest",
     "Description": "The best model for scaling across a wide range of tasks. This is the latest model.",
     "Input Token Limit": 30720,
     "Output Token Limit": 2048,
     "Supported Generation Methods": ["generateContent", "countTokens"],
     "Temperature": 0.9,
     "Top P": 1.0,
     "Top K":  null},
    {"name": "models/gemini-1.5-flash",
     "Version": "001",
     "display_name": "Gemini 1.5 Flash",
     "Description": "Fast and versatile multimodal model for scaling across diverse tasks",
     "Input Token Limit": 1048576,
     "Output Token Limit": 8192,
     "Supported Generation Methods": ["generateContent", "countTokens"],
     "Temperature": 1.0,
     "Top P": 0.95,
     "Top K": 64},
    {"name": "models/gemini-1.5-flash-001",
     "Version": "001",
     "display_name": "Gemini 1.5 Flash 001",
     "Description": "Fast and versatile multimodal model for scaling across diverse tasks",
     "Input Token Limit": 1048576,
     "Output Token Limit": 8192,
     "Supported Generation Methods": ["generateContent",
      "countTokens",
      "createCachedContent"],
     "Temperature": 1.0,
     "Top P": 0.95,
     "Top K": 64},
    {"name": "models/gemini-1.5-flash-latest",
     "Version": "001",
     "display_name": "Gemini 1.5 Flash Latest",
     "Description": "Fast and versatile multimodal model for scaling across diverse tasks",
     "Input Token Limit": 1048576,
     "Output Token Limit": 8192,
     "Supported Generation Methods": ["generateContent", "countTokens"],
     "Temperature": 1.0,
     "Top P": 0.95,
     "Top K": 64},
    {"name": "models/gemini-1.5-pro",
     "Version": "001",
     "display_name": "Gemini 1.5 Pro",
     "Description": "Mid-size multimodal model that supports up to 1 million tokens",
     "Input Token Limit": 1048576,
     "Output Token Limit": 8192,
     "Supported Generation Methods": ["generateContent", "countTokens"],
     "Temperature": 1.0,
     "Top P": 0.95,
     "Top K": 64},
    {"name": "models/gemini-1.5-pro-001",
     "Version": "001",
     "display_name": "Gemini 1.5 Pro 001",
     "Description": "Mid-size multimodal model that supports up to 1 million tokens",
     "Input Token Limit": 1048576,
     "Output Token Limit": 8192,
     "Supported Generation Methods": ["generateContent",
      "countTokens",
      "createCachedContent"],
     "Temperature": 1.0,
     "Top P": 0.95,
     "Top K": 64},
    {"name": "models/gemini-1.5-pro-latest",
     "Version": "001",
     "display_name": "Gemini 1.5 Pro Latest",
     "Description": "Mid-size multimodal model that supports up to 1 million tokens",
     "Input Token Limit": 1048576,
     "Output Token Limit": 8192,
     "Supported Generation Methods": ["generateContent", "countTokens"],
     "Temperature": 1.0,
     "Top P": 0.95,
     "Top K": 64},
    {"name": "models/embedding-001",
     "Version": "001",
     "display_name": "Embedding 001",
     "Description": "Obtain a distributed representation of a text.",
     "Input Token Limit": 2048,
     "Output Token Limit": 1,
     "Supported Generation Methods": ["embedContent"],
     "Temperature":  null,
     "Top P":  null,
     "Top K":  null},
    {"name": "models/text-embedding-004",
     "Version": "004",
     "display_name": "Text Embedding 004",
     "Description": "Obtain a distributed representation of a text.",
     "Input Token Limit": 2048,
     "Output Token Limit": 1,
     "Supported Generation Methods": ["embedContent"],
     "Temperature":  null,
     "Top P":  null,
     "Top K":  null},
    {"name": "models/aqa",
     "Version": "001",
     "display_name": "Model that performs Attributed Question Answering.",
     "Description": "Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.",
     "Input Token Limit": 7168,
     "Output Token Limit": 1024,
     "Supported Generation Methods": ["generateAnswer"],
     "Temperature": 0.2,
     "Top P": 1.0,
     "Top K": 40}]
   